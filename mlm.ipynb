{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BqM4SGsrBVZs"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from torch.nn.functional import softmax\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cUxLXswSDu2N"
   },
   "outputs": [],
   "source": [
    "def predict_masked_token(sentence, tokenizer, model, file_handle, model_type):\n",
    "    if model_type == 'roberta':\n",
    "        sentence = sentence.replace('[MASK]', '<mask>')\n",
    "\n",
    "    input_ids = tokenizer.encode(sentence, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        predictions = outputs[0]\n",
    "\n",
    "    masked_index = torch.where(input_ids == tokenizer.mask_token_id)[1]\n",
    "    masked_logits = predictions[0, masked_index, :]\n",
    "    top_k_weights, top_k_indices = torch.topk(softmax(masked_logits, dim=-1), 2)\n",
    "\n",
    "    predicted_tokens = tokenizer.convert_ids_to_tokens(top_k_indices[0])\n",
    "\n",
    "    if model_type == 'albert':\n",
    "        predicted_tokens = [token.lstrip('_') for token in predicted_tokens]\n",
    "    elif model_type == 'roberta':\n",
    "        predicted_tokens = [token.lstrip('Ġ') for token in predicted_tokens]\n",
    "\n",
    "    file_handle.write(f\"{sentence}\\n\")\n",
    "    file_handle.write(f\"Top predicted word: {predicted_tokens[0]}\\n\")\n",
    "    file_handle.write(f\"Probability of top predicted word {top_k_weights[0][0].item():.8f}\\n\")\n",
    "    file_handle.write(f\"Second predicted word: {predicted_tokens[1]}\\n\")\n",
    "    file_handle.write(f\"Probability of second predicted word {top_k_weights[0][1].item():.8f}\\n\\n\")\n",
    "\n",
    "\n",
    "def process_model(sentences, model_name, tokenizer, model, model_type):\n",
    "    model.eval()\n",
    "    log_filename = f\"{model_name}_predictions.log\"\n",
    "    with open(log_filename, \"w\") as file:\n",
    "        for sentence in tqdm(sentences, desc=f\"Processing {model_name}\"):\n",
    "            predict_masked_token(sentence, tokenizer, model, file, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CRH8rEhjDu0I"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"CustomPrompts_mlm.csv\")\n",
    "sentences = df['sent_masked'].tolist()\n",
    "\n",
    "model_configs = [\n",
    "    (\"bert-base-uncased\", \"bert\"),\n",
    "    (\"albert-base-v2\", \"albert\"),\n",
    "    (\"roberta-base\", \"roberta\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_0KFbK3bDuxm",
    "outputId": "b436587e-9389-4b29-8699-192719dc017f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Processing bert-base-uncased: 100%|██████████| 99/99 [00:21<00:00,  4.60it/s]\n",
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForMaskedLM: ['albert.pooler.bias', 'albert.pooler.weight']\n",
      "- This IS expected if you are initializing AlbertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Processing albert-base-v2: 100%|██████████| 99/99 [00:09<00:00, 10.08it/s]\n",
      "Processing roberta-base: 100%|██████████| 99/99 [00:18<00:00,  5.29it/s]\n"
     ]
    }
   ],
   "source": [
    "for model_name, model_type in model_configs:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "    process_model(sentences, model_name, tokenizer, model, model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iik8vZF-Dush"
   },
   "source": [
    "## Top-1 Metric Eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert Stereotype score: 0.1515\n",
      "albert Stereotype score: 0.0808\n",
      "roberta Stereotype score: 0.1616\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "files = [\n",
    "    (\"mlm/bert/bert_preds.csv\", \"bert\"),\n",
    "    (\"mlm/albert/albert_preds.csv\", \"albert\"),\n",
    "    (\"mlm/roberta/roberta_preds.csv\", \"roberta\")\n",
    "]\n",
    "\n",
    "for file_path, model_name in files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    stereotype_score = df['pred'].sum() / len(df)\n",
    "    print(f\"{model_name} Stereotype score: {stereotype_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
